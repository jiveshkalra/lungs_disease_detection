{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_names = ['Bronchiectasis', 'COPD', 'Healthy', 'Pneumonia', 'URTI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "def preprocessing(audio_file, mode):\n",
    "    # we want to resample audio to 16 kHz\n",
    "    sr_new = 16000 # 16kHz sample rate\n",
    "    x, sr = librosa.load(audio_file, sr=sr_new)\n",
    "\n",
    "    # padding sound \n",
    "    # because duration of sound is dominantly 20 s and all of sample rate is 22050\n",
    "    # we want to pad or truncated sound which is below or above 20 s respectively\n",
    "    max_len = 5 * sr_new  # length of sound array = time x sample rate\n",
    "    if x.shape[0] < max_len:\n",
    "      # padding with zero\n",
    "      pad_width = max_len - x.shape[0]\n",
    "      x = np.pad(x, (0, pad_width))\n",
    "    elif x.shape[0] > max_len:\n",
    "      # truncated\n",
    "      x = x[:max_len]\n",
    "    \n",
    "    if mode == 'mfcc':\n",
    "      feature = librosa.feature.mfcc(y=x, sr=sr_new)\n",
    "    \n",
    "    elif mode == 'log_mel':\n",
    "      feature = librosa.feature.melspectrogram(y=x, sr=sr_new, n_mels=128, fmax=8000)\n",
    "      feature = librosa.power_to_db(feature, ref=np.max) \n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the model  \n",
    "loaded_model = tf.keras.models.load_model(\"prediction_lung_disease_model_v2_without_asthama.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = 'respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/101_1b1_Al_sc_Meditron.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "processed_audio = preprocessing(audio_file,'mfcc').reshape((-1, 20, 157, 1)) \n",
    "new_preds = loaded_model.predict(processed_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'URTI'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_classpreds = np.argmax(new_preds, axis=1)\n",
    "c_names[new_classpreds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
